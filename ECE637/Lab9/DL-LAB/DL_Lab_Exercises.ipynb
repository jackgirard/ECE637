{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Lab_Exercises.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["kBSX7VY10uvp"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kLTpDVQk0ozE","colab_type":"text"},"cell_type":"markdown","source":["# ECE 637 Deep Learning Lab Exercises\n"]},{"metadata":{"id":"FsD730rXywMj","colab_type":"text"},"cell_type":"markdown","source":["Name: *Your name*"]},{"metadata":{"id":"q8lAlbvv1d2e","colab_type":"text"},"cell_type":"markdown","source":["# Section 1"]},{"metadata":{"id":"JqJeDZYM1LbR","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 1.1\n","\n","1.   Create two lists, `A` and `B`: `A` contains 3 arbitrary numbers and `B` contains 3 arbitrary strings.\n","2.   Concatenate two lists into a bigger list and name that list `C`. \n","3.   Print the first element in `C`.\n","4.   Print the second last element in `C` via negative indexing.\n","5.   Remove the second element of `A` from `C`.\n","6.   Print `C` again."]},{"metadata":{"id":"-kmPdZCA0uRl","colab_type":"code","colab":{}},"cell_type":"code","source":["#  ----------- YOUR CODE -----------"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kBSX7VY10uvp","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 1.2\n","In this exercise, you will use a low-pass IIR filter to remove noise from a sine-wave signal.\n","\n","You should organize your plots in a 3x1 subplot format.\n","\n","1. Generate a discrete-time signal, `x`, by sampling a 2Hz continuous time sine wave signal with peak amplitude 1 from time 0s to 10s and at a sampling frequency of 500 Hz. Display the signal, `x`, from time 4s to 6s in the first row of a 3x1 subplot with the title \"original signal\".\n","\n","2. Add Gaussian white random noise with 0 mean and standard deviation  0.1 to `x` and call it `x_n` . Display `x_n` from 4s to 6s on the second row of the subplot with the title \"input signal\".\n","\n","3. Design a low-pass butterworth IIR filter of order 5 with a cut-off frequency of 4Hz, designed to filter out the noise.  Hint: Use the [signal.butter](https://docs.scipy.org/doc/scipy-1.1.0/reference/generated/scipy.signal.butter.html#scipy.signal.butter) function and note that the frequencies are relative to the Nyquist frequency. Apply the IIR filter to `x_n`, and name the output `y`. Hint: Use [signal.filtfilt](https://docs.scipy.org/doc/scipy-1.1.0/reference/generated/scipy.signal.filtfilt.html#scipy.signal.filtfilt) function. Plot `y` from 4s to 6s on the third row of the subplot with the title \"filtered signal\".\n"]},{"metadata":{"id":"tzpg6gZ_004O","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np                     # import the numpy packages and use a shorter alising name\n","import matplotlib.pyplot as plt        # again import the matplotlib's pyplot packages\n","from scipy import signal               # import a minor package signal from scipy\n","plt.figure(figsize=(10, 15))           # fix the plot size\n","\n","#  ----------- YOUR CODE -----------\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KU9ewdGe2uf7","colab_type":"text"},"cell_type":"markdown","source":["# Section 2"]},{"metadata":{"id":"NDTwJQ3K2xAE","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 2.1\n","\n","*   Plot the third image in the test data set\n","*   Find the correspoding label for the this image and make it the title of the figure\n"]},{"metadata":{"id":"mkq2IPCa2wKT","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","\n","#  ----------- YOUR CODE -----------"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QFwNGjZZo7CP","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 2.2\n","It is usually helpful to have an accuracy plot as well as a loss value plot to get an intuitive sense of how effectively the model is being trained. \n","\n","* Add code to this example for plotting two graphs with the following requirements:\n","  - Use a 1x2 subplot with the left subplot showing the loss function and right subplot showing the accuracy.\n","  - For each graph, plot the value with respect to epochs. Clearly label the x-axis, y-axis and the title.\n","\n","(Hint: The value of of loss and accuracy are stored in the `hist` variable. \n","Try to print out `hist.history` and `his.history.keys()`.)"]},{"metadata":{"id":"5X9GsmEzo_R1","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.datasets import mnist\n","from keras import models\n","from keras import layers\n","from keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","\n","network = models.Sequential()\n","network.add(layers.Flatten(input_shape=(28, 28, 1)))\n","network.add(layers.Dense(512, activation='relu'))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.summary()\n","\n","network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","train_images_nor = train_images.astype('float32') / 255\n","test_images_nor = test_images.astype('float32') / 255\n","\n","train_labels_cat = to_categorical(train_labels)\n","test_labels_cat = to_categorical(test_labels)\n","\n","hist = network.fit(train_images_nor, train_labels_cat, epochs=5, batch_size=128)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w58heEcSeAui","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 4))\n","\n","#  ----------- YOUR CODE -----------\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GGKlyKbW2OZA","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 2.3\n","Use the dense network from Section 2 as the basis to construct of a deeper network with\n","\n","*  5 dense hidden layers with dimensions [512, 256, 128, 64, 32] each of which uses a ReLU non-linearity\n","\n","**Question:** Will the accuracy on the testing data always get better if we keep making the neural network larger?\n","\n"]},{"metadata":{"id":"ToF8yn8ahe-O","colab_type":"text"},"cell_type":"markdown","source":["*Your answer*"]},{"metadata":{"id":"pgjEFVPo23eG","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras import models\n","from keras import layers\n","\n","#  ----------- YOUR CODE -----------\n","# network = ...\n","\n","network.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jx2LETbcX6IB","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","\n","\n","network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","train_images_nor = train_images.astype('float32') / 255\n","test_images_nor = test_images.astype('float32') / 255\n","\n","train_labels_cat = to_categorical(train_labels)\n","test_labels_cat = to_categorical(test_labels)\n","\n","hist = network.fit(train_images_nor, train_labels_cat, epochs=5, batch_size=128)\n","\n","test_loss, test_acc = network.evaluate(test_images_nor, test_labels_cat)\n","print('test_accuracy:', test_acc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AsXd0j1Njhba","colab_type":"text"},"cell_type":"markdown","source":["# Section 3"]},{"metadata":{"id":"fi-l9cBf2_nB","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 3.1\n","In this exercise, you will access the relationship between the feature extraction layer and classification layer. The example above uses two sets of convolutional layers and pooling layers in the feature extraction layer and two dense layers in the classification layers. The overall performance is around 98% for both training and test dataset. In this exercise, try to create a similar CNN network with the following requirements:\n","\n","*   Achieve the overall accuracy higher than 99% for training and testing dataset.\n","*  Keep the total number of parameters used in the network lower than 100,000."]},{"metadata":{"id":"tOr0NOv5-hJo","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras import models\n","from keras import layers\n","\n","network = models.Sequential()\n","\n","#  ----------- YOUR CODE -----------"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FYFNcxkb639j","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import mnist\n","from keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images_nor = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images_nor = test_images.astype('float32') / 255\n","\n","train_labels_cat = to_categorical(train_labels)\n","test_labels_cat = to_categorical(test_labels)\n","\n","network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","network.fit(train_images_nor, train_labels_cat, epochs=5, batch_size=128)\n","\n","test_loss, test_acc = network.evaluate(test_images_nor, test_labels_cat)\n","print('test_accuracy:', test_acc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c5F_kMFw3dMo","colab_type":"text"},"cell_type":"markdown","source":["# Section 4"]},{"metadata":{"id":"xT1mPktl4MsW","colab_type":"text"},"cell_type":"markdown","source":["## Exercise 4.1\n","In this exercise you will need to create the entire neural network that does image denoising tasks. Try to mimic the code provided above and follow the structure as provided in the instructions below."]},{"metadata":{"id":"MGCURYAN4Zu-","colab_type":"text"},"cell_type":"markdown","source":["**Task 1**: Create the datasets\n","1.   Import necessary packages\n","2.   Load the MNIST data from Keras, and save the training dataset images as `train_images`, save the test dataset images as `test_images`\n","3.   Add additive white gaussian noise to the train images as well as the test images and save the noisy images to `train_images_noisy` and `test_images_noisy` respectivly. The noise should have mean value 0, and standard deviation 0.4. (Hint: Use [np.random.normal](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.normal.html))\n","4.   Show the first image in the training dataset as well as the test dataset (plot the images in 1 x 2 subplot form)"]},{"metadata":{"id":"fNujLacs4YtE","colab_type":"code","colab":{}},"cell_type":"code","source":["#  ----------- YOUR CODE -----------"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kHPTiHi54gzu","colab_type":"text"},"cell_type":"markdown","source":["**Task 2**: Create the neural network model\n","1.   Create a sequential model called `encoder` with the following layers sequentially:\n","  * convolutional layer with `32` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function.\n","  * max pooling layer with `2x2` kernel size\n","  * convolutional layer with `16` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function.\n","  * max pooling layer with `2x2` kernel size\n","  * convolutional layer with `8` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function and name the layer as `'convOutput'`.\n","  * flatten layer\n","  * dense layer with output dimension as `encoding_dim`  with `'relu'` activition function.\n","2.   Create a sequential model called `decoder` with the following layers sequentially:\n","  * dense layer with the input dimension as `encoding_dim` and the output dimension as the product of the output dimenstions of the `'convOutput'` layer.\n","  * reshape layer that convert the tensor into the same shape as `'convOutput'`\n","  * convolutional layer with `8` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function.\n","  * upsampling layer with `2x2` kernel size\n","  * convolutional layer with `16` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function.\n","  * upsampling layer with `2x2` kernel size\n","  * convolutional layer with `32` output channels, `3x3` kernel size, and the padding convention `'same'` with `'relu'` activition function\n","  * convolutional layer with `1` output channels, `3x3` kernel size, and the padding convention `'same'` with `'sigmoid'` activition function\n","3. Create a sequential model called `autoencoder` with the following layers sequentially:\n","  * `encoder` model\n","  * `decoder` model\n"," "]},{"metadata":{"id":"XLFvC76d6R6D","colab_type":"code","colab":{}},"cell_type":"code","source":["#  ----------- YOUR CODE -----------\n","encoding_dim = 32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qAXDioTikfOG","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder.summary()\n","decoder.summary()\n","autoencoder.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GQfdKLjjkxMM","colab_type":"text"},"cell_type":"markdown","source":["**Task 3**: Create the neural network model  \n","\n","Fit the model to the training data using the following hyper-parameters:\n","  * `adam` optimizer\n","  * `binary_crossentropy` loss function\n","  * `20` training epochs\n","  * batch size as `256`\n","  * set `shuffle` as `True`\n","  \n","Compile the model and fit ..."]},{"metadata":{"id":"c3cR_RjRkvXI","colab_type":"code","colab":{}},"cell_type":"code","source":["autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","history = autoencoder.fit(train_images_noisy, train_images_nor, \n","                epochs=20, \n","                batch_size=256,\n","                shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NDEMXTFdkwL3","colab_type":"text"},"cell_type":"markdown","source":["**Task 4**: Create the neural network model (No need to write code, just run the following commands)"]},{"metadata":{"id":"upL0lofw9jgo","colab_type":"code","colab":{}},"cell_type":"code","source":["def showImages(input_imgs, encoded_imgs, output_imgs, size=1.5, groundTruth=None):\n","\n","  numCols = 3 if groundTruth is None else 4\n","  \n","  num_images = input_imgs.shape[0]\n","      \n","  encoded_imgs = encoded_imgs.reshape((num_images, 1, -1))\n","    \n","\n","  plt.figure(figsize=((numCols+encoded_imgs.shape[2]/input_imgs.shape[2])*size, num_images*size))\n","\n","  pltIdx = 0\n","  col = 0\n","  for i in range(0, num_images):\n","\n","    col += 1\n","    # plot input image\n","    pltIdx += 1\n","    ax = plt.subplot(num_images, numCols, pltIdx)\n","    plt.imshow(input_imgs[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if col == 1:\n","      plt.title('Input Image')\n","\n","    # plot encoding\n","    pltIdx += 1\n","    ax = plt.subplot(num_images, numCols, pltIdx)\n","    plt.imshow(encoded_imgs[i])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if col == 1:\n","      plt.title('Encoded Image')\n","\n","    # plot reconstructed image\n","    pltIdx += 1\n","    ax = plt.subplot(num_images, numCols, pltIdx)\n","    plt.imshow(output_imgs[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if col == 1:\n","      plt.title('Reconstructed Image')\n","  \n","    if numCols == 4:\n","      # plot ground truth image\n","      pltIdx += 1\n","      ax = plt.subplot(num_images, numCols, pltIdx)\n","      plt.imshow(groundTruth[i].reshape(28, 28))\n","      plt.gray()\n","      ax.get_xaxis().set_visible(False)\n","      ax.get_yaxis().set_visible(False)\n","      \n","      if col == 1:\n","        plt.title('Ground Truth')\n","\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WqL4ZnZ59w3e","colab_type":"code","colab":{}},"cell_type":"code","source":["num_images = 10\n","\n","input_labels = test_labels[0:num_images]\n","I = np.argsort(input_labels)\n","\n","input_imgs = test_images_noisy[I]\n","\n","encoded_imgs = encoder.predict(test_images_noisy[I])\n","output_imgs = decoder.predict(encoded_imgs)\n","\n","showImages(input_imgs, encoded_imgs, output_imgs, size=2, groundTruth=test_images_nor[I])"],"execution_count":0,"outputs":[]}]}